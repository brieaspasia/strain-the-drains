---
title: "Micro_stats"
author: "Brie Sherow"
date: "09/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, warning=FALSE, message=FALSE, results='hide', include=FALSE}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(tidyr) #long & wide formats
library(reshape2) #melt function for wide and long formats
library(stats) #R stats functions
library(broom) #create summaries from stats objects
library(car) #lm regression
library(MASS) #stats
library(lme4) #glmer function
library(DHARMa) #testing model diagnostics
library(glmmTMB) #fit zero-inflated negative binomial
library(lattice) #fourth corner heatmap
library(corrplot) #co-occurrence matrix
library(gclus) #co-occurrence matrix
library(broom.mixed) #regression tables
library(vegan) #ordination
library(emmeans)
library(ComplexHeatmap)
library(RColorBrewer)
library(heatmaply)
library(cowplot) #minimal backgrounds for ggplot

```

```{r create-df, warning=FALSE, message=FALSE, results='hide', include=FALSE}
#create survey count  

        #load item counts
        micro <- read.csv(file="Data/200630_micro.csv", 
                         header=T, sep=",") 

        #remove duplicate entries
        micro <- unique(micro[!duplicated(micro),])
        
        micro$tot <- as.integer(micro$tot)
        
        micro <- micro %>%
        group_by(event_id, item) %>%
        summarise(sum=sum(tot)) %>%
        ungroup()
        
        #load events
        event <- read.csv(file="Data/2101_event.csv", 
                         header=T, sep=",") 
        
        #join event info to item count
        survey_count <- left_join(event, micro, by="event_id")
        
        survey_count <- survey_count %>%
          dplyr::select(-event.tot, -event.wt, -vol, -hr, event_date)
        
#create abundance data with all possible debris items and zero values
      
      #create full list of possible items (only four micro categories)
      item <- as.data.frame(unique(micro$item))
      
      
      #create a df of all possible items at all survey events, complete with zeros
      abund <- full_join(survey_count, item, by=c("item" = "unique(micro$item)"))
      
      #data long to wide
      abund_wide <- spread(abund, item, sum)
      
      abund_wide <- abund_wide %>%
        dplyr::select(event_id, "Glass beads", "Secondary plastics", "Primary plastics", "Polystyrene balls")
      
      #replace na values with 0
      abund_wide[is.na(abund_wide)] <- 0
      
      #transform back to long but now with the full items list and zero data
      abund_long <- melt(abund_wide, id.vars="event_id")
     
      df <- left_join(abund_long, event, by="event_id")
      
      #load sites
          site <- read.csv(file="Data/200619_site.csv", 
                           header=T, sep=",") 
      
            #join LGA and luz to df
          df <- left_join(df, site, by = "Asset.ID")
      
      
      df <- df %>%
        dplyr::select(-event_date, -event.tot, -event.wt, -vol, -hr, -Site, -Latitude, -Longitude) %>% #remove duplicate columns
        rename(item=variable, #rename columns
               sum=value,
               asset_id = Asset.ID,
               cycle=Cycle,
               LUZ = Land.use.zone) %>% 
        mutate(asset_id=as.factor(asset_id), #classify columns correctly  
             item=as.factor(item),
             LGA=as.factor(LGA),
             LUZ=as.factor(LUZ),
             event_id=as.factor(event_id),
             cycle=as.factor(cycle),
             date=dmy(date)
             )
      
      
#Combine C8 and C9    
     #isolate C8
    C8 <- df %>%
      filter(cycle == "C8")
    
    #isolate C9
    C9 <- df %>%
      filter(cycle == "C9")
    
    #join C8 and C9 by unique drain and item to capture double surveys
    t <- left_join(C9, C8, by=c("asset_id"="asset_id", "item" = "item"))
    t$sum.y[is.na(t$sum.y)] <- 0 #change na to 0
    
    t <- t %>%
      mutate(combined_sum = sum.y + sum.x) %>% #add C8 and C9 together
      dplyr::select(event_id.x, item, combined_sum)
    
    df <- df %>% 
      left_join(t, by = c("event_id"="event_id.x", "item"="item")) %>%
      filter(cycle != "C8") %>%
      mutate(combined_sum = replace_na(combined_sum, 0),
              sum2 = ifelse(cycle != "C9", sum, 0),
              final_sum = sum2 + combined_sum) %>%
      dplyr::select(-sum2, -sum, -combined_sum) %>%
      rename(sum = final_sum)
    
        t <- df %>%
      group_by(LUZ) %>%
      summarise(total=sum(sum)) %>% #>90% in industrial
      mutate(pct = total/737651  * 100)
```

```{r micro-plot}
df_item = df %>% group_by(LUZ, item) %>% summarise(total = sum(sum), sd = sd(sum))

# df_item = df_item %>% mutate(sum = sum*10^-3, sd = sd*10^-3) %>% filter(sum >0.2)

p <- ggplot(df_item, aes(x = LUZ, y = total, fill = item)) +
        geom_bar(stat="identity", position="dodge") +
        geom_text(aes(y = total + sd, label = round(total,2)), 
                  position = position_dodge(width =0.9), 
                  vjust = -0.5, color = "black", size = 3) +
        geom_errorbar(aes(ymin = total - sd, ymax = total + sd), 
                      width = .2, position = position_dodge(.9)) +
        theme_hc() + 
        scale_fill_brewer(
          type = "qual", palette = 8,
          direction = 2, aesthetics = "fill"
        ) + 
        # theme(axis.text.x = element_text(angle = 70)) +
        ggtitle("Counts of microplastics (< 5mm) by Land Use") +
        labs(y = "Microplastic counts (thousands)", x="") +
        theme(axis.text.x=element_text(color = "black", size=11, 
                                 vjust=.8, angle=30, hjust=0.8))

p
```


```{r avg-items-per-lockdown, warning=FALSE, message=FALSE}

mic_item_per_cycle <- df %>%
  group_by(date, covid, LUZ, item) %>%
  summarise(cycle_sum = sum(sum))

mic_item_order <- mic_item_per_cycle %>%
  group_by(item) %>%
  mutate(total=sum(cycle_sum)) %>%
  arrange(desc(total)) %>%
  dplyr::select(item, total) %>%
  distinct

#create vector from order items
mic_order <- mic_item_order$item 
mic_order <- unlist(mic_order)

mic_item_per_cycle$item <- factor(mic_item_per_cycle$item, 
                                  levels = mic_order)

covid_lvl <- data.frame(name = c("1", "2"),
                   start = as.Date(c("2019-10-29", "2020-03-15")),
                   end = as.Date(c("2020-03-15", "2020-10-17")),
                   level = c("Pre-Covid", "During Covid"),
                   stringsAsFactors = FALSE) %>%
  mutate(median_x = start + floor((end-start)/2))


mic_p <- ggplot() +
  geom_rect(data=covid_lvl, aes(NULL, NULL, xmin=start, xmax=end, fill=level, 
                                ymin= -Inf, ymax=Inf), alpha=0.1) +
  labs(fill="Covid-19 lockdown", linetype="Land Use Zones", colour="Land Use Zones",
       x="Date", y="Debris count per survey cycle") +
  # geom_point(data=item_per_cycle, aes(date, cycle_sum, color=LUZ)) +
  geom_line(data=mic_item_per_cycle, aes(date, cycle_sum, linetype=LUZ, color=LUZ)) +
  theme(axis.text.x=element_text(angle=45, vjust=0.75, hjust=0.8)) +
  facet_wrap(~item, scales="free_y") +
  geom_vline(xintercept = as.numeric(as.Date("2020-06-30")), linetype=4)
mic_p

#reference: https://plotly.com/ggplot2/geom_rect/ tutorial for geom_rect background
```
```{r percent-change-delta-micro}
#refer to delta method
#https://stats.stackexchange.com/questions/64652/calculating-standard-deviation-associated-with-percentage-change
pct_change <- df %>%
  group_by(covid, asset_id, LUZ) %>% #look at items per asset both cov
  mutate(assetMean=mean(sum)) %>% #mean of item btwn 8 cycles at each asset per covid level
  ungroup() %>%
  dplyr::select(covid, asset_id, LUZ, assetMean) %>% #select vars
  unique() #remove duplicates from survey cycle
  
# Split data into each item
pct_change <- droplevels(pct_change)
ls.data_split <- split(pct_change, f = pct_change$LUZ)


delta_LUZ_micro = purrr::map_df(ls.data_split, function(x){

x1 = x %>% filter(covid == 1)
# x1$assetMean = ifelse(x1$assetMean == 0, 0.00001, x1$assetMean)

x2 = x %>% filter(covid == 2) %>% dplyr::select(asset_id, assetMean)
# x2$assetMean = ifelse(x2$assetMean == 0, 0.00001, x2$assetMean)

xV = var(x1$assetMean)
x_mean = mean(x1$assetMean)

yV = var(x2$assetMean)
y_mean = mean(x2$assetMean)

num = (yV*x_mean^2) - 2*cov(x1$assetMean, x2$assetMean)*x_mean*y_mean + (xV*y_mean^2)
denom = x_mean^4

se_pcc = 100*sqrt(num/denom)

pcc = ((y_mean - x_mean)/x_mean) *100

# Output array
LUZ = unique(x$LUZ)
avg = pcc
se = se_pcc

out = data.frame(LUZ, avg, se)


})

delta_LUZ_micro <- delta_LUZ_micro %>%
  mutate(pos = avg >= 0,
         SE_lower = avg-se,
         SE_upper = avg+se)

p_delta_LUZ_micro <- delta_LUZ_micro %>%
  mutate(LUZ=as.factor(LUZ),
         LUZ=fct_reorder(LUZ, avg)) %>%
  ggplot( aes(x=avg, y=LUZ, fill=pos)) +
  geom_bar(stat="identity") +
  geom_errorbar(aes(xmin=SE_lower, xmax=SE_upper, width=0.2)) 
  # theme(legend.position = "none",
  #       panel.grid = element_blank(),
  #       axis.title = element_blank(),
  #       axis.text = element_blank(),
  #       panel.background = element_blank())

p_delta_LUZ_micro

# svg("images/p_change_delta.svg", height=7, width=12)
# plot(p_change_delta)
# dev.off()

```
```


```{r data-mod, warning=FALSE, message=FALSE}
#aggregate data
mod <- df %>%
  group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
  summarise(sum=sum(sum)) %>%
  ungroup() %>%
  # filter(cycle %in% paste0("C",1:7)) %>%
  mutate(LGA = as.factor(LGA),
         LUZ = as.factor(fct_relevel(LUZ, "CBD", "Shopping Centre", "Public Transport Terminal", "Industrial Precinct")),
         covid = as.factor(covid),
         cycle = as.factor(cycle))
       
#create model
m  <- glmmTMB(sum ~ #Debris count per survey event
                LUZ * covid + #predicted by land use effected by covid
                 (1|LGA/asset_id) + (1|cycle), #suburb random effect
               family=nbinom2(), #negative binomial to deal with count data and zeros
               data = mod)

emmeans(m, pairwise~covid|LUZ, type="response")

#create predictor df
nd <- expand.grid(covid = unique(mod$covid),
                  LUZ = unique(mod$LUZ),
                  LGA = NA,
                  asset_id = NA,
                  cycle = NA)

#predict mean values of response variable
pred <- predict(object=m,
                newdata=nd,
                se.fit=T,
                re.form=NA)

#create standard error for graphing
nd$Total <- exp(pred$fit)
nd$SE_upper <- exp(pred$fit + pred$se.fit)
nd$SE_lower <- exp(pred$fit - pred$se.fit)

# New facet label names for covid variable
nd$covid <- factor(nd$covid, levels = c("1", "2"),
                  labels = c("Pre-Covid", "During Covid"))

#create plot
p_micro <- ggplot(nd, aes(y=Total, x=LUZ, fill=covid)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  labs(title="Micro debris count (every 6 weeks)",
       subtitle="By land use zone and covid restriction",
       x="", y="Total debris items per asset", tag="") 

p_micro

#create plot
p_micro <- ggplot(nd, aes(y=Total, x=LUZ, fill=covid)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  labs(title="Micro debris count (every 6 weeks)",
       subtitle="By land use zone and covid restriction",
       x="", y="Total debris items per asset", tag="") +
      theme(legend.position = "none",
        panel.grid = element_blank(),
        axis.title = element_blank(),
        axis.text = element_blank(),
        panel.background = element_blank())

svg("images/p_micro.svg", height=7, width=12)
plot(p_micro)
dev.off()
```

```{r dharma-effect}
simulationOutput <- simulateResiduals(fittedModel = m, plot=T)
  
plotResiduals(simulationOutput)
testUniformity(simulationOutput) #tests if the overall distribution conforms to expectations
# testOutliers(simulationOutput) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput) #tests if the simulated dispersion is equal to the observed dispersion
#testQuantiles(simulationOutput) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput) #tests if there are more zeros than expected
```

```{r data-mod-top5, warning=FALSE, message=FALSE}
# Function loop: each item

#Top 4 plus OH&S
txt<- df %>%
  filter(item %in% c("Primary plastics", 
                     "Secondary plastics",
                     "Polystyrene balls")) %>% 
  distinct(item)%>%
  pull(item) %>% 
  droplevels()

# Purrr
library(purrr)

pred_df <- purrr::map_df(txt, function(x){
  
  temp_df <- df %>% 
    filter(item == paste0(x)) %>%
    group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
    summarise(sum=sum(sum)) %>%
    ungroup() %>%
    # filter(cycle %in% paste0("C",1:7)) %>%
    mutate(LGA = as.factor(LGA),
           LUZ = as.factor(fct_relevel(LUZ, "CBD", "Shopping Centre", "Public Transport Terminal", "Industrial Precinct")),
           covid = as.factor(covid),
           cycle = droplevels(as.factor(cycle)),
           item = x)
 
 #create model
 m_temp  <- glmmTMB(sum ~ #Debris count per survey event
                   LUZ * covid + #predicted by land use effected by covid
                   (1|LGA/asset_id) + (1|cycle), #suburb random effect
                   family=nbinom2(), #negative binomial to deal with count data and zeros
                   data = temp_df)

 nd_temp <- expand.grid(covid = unique(temp_df$covid),
                       LUZ = unique(temp_df$LUZ),
                       LGA = NA,
                       asset_id = NA,
                       cycle = NA)

 pred_temp <- predict(object=m_temp,
                     newdata=nd_temp,
                     se.fit=T,
                     re.form=NA)
 
 #creating standard error for graphing
 nd_temp$Total <- exp(pred_temp$fit)
 nd_temp$SE_upper <- exp(pred_temp$fit + pred_temp$se.fit)
 nd_temp$SE_lower <- exp(pred_temp$fit - pred_temp$se.fit)
 nd_temp$item <- x
 
 return(nd_temp)
 
 })

#DHARMA results here are not great for dispersion
simulationOutput <- simulateResiduals(fittedModel = m_temp, plot=T)
plotResiduals(simulationOutput)
testUniformity(simulationOutput) #tests if the overall distribution conforms to expectations
# testOutliers(simulationOutput) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput) #tests if the simulated dispersion is equal to the observed dispersion
#testQuantiles(simulationOutput) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput) #tests if there are more zeros than expected

# New facet label names for covid variable
pred_df$covid <- factor(pred_df$covid, levels = c("1", "2"),
                  labels = c("Pre-Covid", "During Covid"))


 #create plot
p_all <- ggplot(pred_df, aes(y=Total, x=item, fill=covid)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  labs(title="Debris count per asset (every 6 weeks)",
       subtitle="By covid restriction",
       x="", y="Total debris items per asset", tag="") +
  facet_wrap(~LUZ, scales="free_y") +
  guides(x =  guide_axis(angle = 45)) 

p_all
``` 

```{r MDS-LGA}

#create abundance long format
 abund_long <- df %>%
    group_by(LGA, LUZ, covid, item) %>% 
    summarise(sum=sum(sum)) %>% #total of each item type per survey event
  ungroup()

#convert to data wide
  abund <- spread(abund_long, item, sum) 
  abund <- abund[rowSums(abund[4:7])>0,] #remove zero rows
  
  com <- abund[4:7]
  
  #removing debris items that are zero across all surveys
  com <- com[, which(colSums(com) != 0)] #remove zero columns
  
  
  ord <- metaMDS(com)
  
  data.scores <- as.data.frame(scores(ord)) #create df of ord points
  data.scores$LUZ <- abund$LUZ
  data.scores$covid <- abund$covid
  data.scores <- data.scores %>%
    mutate(covid = as.factor(covid),
           LUZ = as.factor(LUZ))
  
  species.scores <- as.data.frame(scores(ord, "species"))
  species.scores$item <- rownames(species.scores) #create item id column
  
  
#Hull data
CBD <- data.scores[data.scores$LUZ == "CBD", ][chull(data.scores[data.scores$LUZ ==
    "CBD", c("NMDS1", "NMDS2")]), ]  # hull values for CBD
Transport <- data.scores[data.scores$LUZ == "Public Transport Terminal", ][chull(data.scores[data.scores$LUZ ==
    "Public Transport Terminal", c("NMDS1", "NMDS2")]), ]  # hull values for Transport
Indus <- data.scores[data.scores$LUZ == "Industrial Precinct", ][chull(data.scores[data.scores$LUZ == "Industrial Precinct", c("NMDS1", "NMDS2")]), ]  # hull values for Industry
Shop <- data.scores[data.scores$LUZ == "Shopping Centre", ][chull(data.scores[data.scores$LUZ ==
    "Shopping Centre", c("NMDS1", "NMDS2")]), ]  # hull values for shopping

#create polygons
hull.data <- rbind(CBD, Transport, Indus, Shop)  #combine groups
hull.data

  
ggplot() +
  geom_polygon(data=hull.data,aes(x=NMDS1,y=NMDS2,fill=LUZ,group=LUZ),alpha=0.1) +
  geom_text(data=species.scores,aes(x=NMDS1,y=NMDS2, label=item)) +
  geom_point(data=data.scores, 
             aes(x=NMDS1, y=NMDS2, colour=LUZ, shape=covid), alpha=0.8) + 
  coord_equal() +
  theme_bw()

#https://chrischizinski.github.io/rstats/vegan-ggplot2/

#colour symbols to land use and change shape to covid
#arrows (vectors that show how items are pulling/pushing)
```

```{r adonis-pairwise}
df.adonis <- adonis(com ~ data.scores$LUZ*data.scores$covid, permutations=999, method="bray")
df.adonis

#testing land use dispersion
df.dis <- vegdist(com, method = "bray") # make a distance matrix
df.betadisper.luz <- betadisper(df.dis, data.scores$LUZ) # test dispersion
df.betadisper.luz
permutest(df.betadisper.luz) #dispersion not significant

#testing covid dispersion
df.dis <- vegdist(com, method = "bray") # make a distance matrix
df.betadisper.cov <- betadisper(df.dis, data.scores$covid) # test dispersion
df.betadisper.cov
permutest(df.betadisper.cov) #dispersion not significant
```
