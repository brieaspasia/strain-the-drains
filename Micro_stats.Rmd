---
title: "Micro_stats"
author: "Brie Sherow"
date: "09/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, warning=FALSE, message=FALSE, results='hide', include=FALSE}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(tidyr) #long & wide formats
library(reshape2) #melt function for wide and long formats
library(stats) #R stats functions
library(broom) #create summaries from stats objects
library(car) #lm regression
library(MASS) #stats
library(lme4) #glmer function
library(DHARMa) #testing model diagnostics
library(glmmTMB) #fit zero-inflated negative binomial
library(lattice) #fourth corner heatmap
library(corrplot) #co-occurrence matrix
library(gclus) #co-occurrence matrix
library(broom.mixed) #regression tables
library(vegan) #ordination
library(emmeans)
library(ComplexHeatmap)
library(RColorBrewer)
library(heatmaply)
library(cowplot) #minimal backgrounds for ggplot

```

```{r create-df, warning=FALSE, message=FALSE, results='hide', include=FALSE}
#create survey count  

        #load item counts
        micro <- read.csv(file="Data/200630_micro.csv", 
                         header=T, sep=",") 

        #remove duplicate entries
        micro <- unique(micro[!duplicated(micro),])
        
        micro <- micro %>%
        group_by(event_id, Type) %>%
        summarise(sum=sum(tot)) %>%
        ungroup()
        
        #load events
        event <- read.csv(file="Data/2101_event.csv", 
                         header=T, sep=",") 
        
        #join event info to item count
        survey_count <- left_join(event, item, by="event_id")
        
        survey_count <- survey_count %>%
          dplyr::select(-event.tot, -event.wt, -vol, -hr, event_date)
        
#create abundance data with all possible debris items and zero values
      
      #create full list of possible items (only five micro categories)
      type <- as.data.frame(unique(item$Type))
      
      
      #create a df of all possible items at all survey events, complete with zeros
      abund <- full_join(survey_count, type, by=c("Type" = "unique(item$Type)"))
      
      #data long to wide
      abund_wide <- spread(abund, Type, sum)
      
      abund_wide <- abund_wide %>%
        dplyr::select(event_id, "Glass beads", "Plastic chips", "Plastic shards", "Plastic resin pellet", "Polystyrene balls")
      
      #replace na values with 0
      abund_wide[is.na(abund_wide)] <- 0
      
      #transform back to long but now with the full items list and zero data
      abund_long <- melt(abund_wide, id.vars="event_id")
     
      df <- left_join(abund_long, event, by="event_id")
      
      #load sites
          site <- read.csv(file="Data/200619_site.csv", 
                           header=T, sep=",") 
      
            #join LGA and luz to df
          df <- left_join(df, site, by = "Asset.ID")
      
      
      df <- df %>%
        dplyr::select(-event_date, -event.tot, -event.wt, -vol, -hr, -Site, -Latitude, -Longitude) %>% #remove duplicate columns
        rename(item=variable, #rename columns
               sum=value,
               asset_id = Asset.ID,
               cycle=Cycle,
               LUZ = Land.use.zone) %>% 
        mutate(asset_id=as.factor(asset_id), #classify columns correctly  
             item=as.factor(item),
             LGA=as.factor(LGA),
             LUZ=as.factor(LUZ),
             event_id=as.factor(event_id),
             cycle=as.factor(cycle),
             date=dmy(date)
             )
      
      
      # write.csv(df,here("Data","micro_view.csv"))
```

```{r heatmap-item-top15, warning=FALSE, message=FALSE}

preCov <- df %>%
  filter(cycle %in% c("C1", "C2", "C3", "C4")) %>%
  group_by(LUZ) %>%
  mutate(total_LUZ=sum(sum)) %>%
  ungroup() %>%
  group_by(LUZ, item) %>%
  mutate(total_itemLUZ = sum(sum)) %>%
  ungroup() %>%
  mutate(pct = (total_itemLUZ/total_LUZ)*100) %>%
  dplyr::select(item, LUZ, pct) %>%
  unique() %>%
  spread(item, pct) %>%
  column_to_rownames(var="LUZ")

mat <- data.matrix(preCov) #matrix for heatmap
mat <- round(mat,0)
mat2 = ifelse(mat <= 0.99,"<1",as.character(round(mat,2))) #matrix for labels


col_ha <- HeatmapAnnotation(Region = anno_text(colnames(mat), location = 1, rot = 60, 
                              just = "right"))

Heatmap(log10(mat+0.1), 
        name = "Debris count (percentage per land use zone)", 
        heatmap_legend_param  = list(color_bar = "continuous", at = c(-2.6,3.5),
                      title = "Debris counts (% total)",labels = c("Low", "High"),
                      grid_width = unit(0.8, "cm"),
                      legend_height = unit(5, "cm"),
                      title_position = "leftcenter-rot"), 
        col= colorRampPalette(brewer.pal(8, "PRGn"))(25),
        row_dend_reorder = TRUE, 
        row_order = sort(rownames(mat)),
        show_column_dend = FALSE,
        show_row_dend = FALSE,
        bottom_annotation = col_ha,
        show_row_names = TRUE,
        row_names_side = "left",
        show_column_names = FALSE,
        border = TRUE,
        column_title = "Percentage of top 15 debris items per land use zone",
        #percentage label
        cell_fun = function(j, i, x, y, width, height, fill) {
        grid.text(sprintf("%s", mat2[i, j],"%"), x, y, gp = gpar(fontsize = 10))},
        )

```

```{r avg-items-per-lockdown, warning=FALSE, message=FALSE}

item_per_cycle <- df %>%
  group_by(date, covid, LUZ, item) %>%
  summarise(cycle_sum = sum(sum))

covid_lvl <- data.frame(name = c("1", "2", "3", "4", "5"),
                   start = as.Date(c("2019-10-29", "2020-03-14", "2020-03-19", "2020-06-21",
                             "2020-07-06")),
                   end = as.Date(c("2020-03-14", "2020-03-19", "2020-06-21", "2020-07-06", 
                           "2020-10-17")),
                   level = c("No lockdown", "Moderate lockdown", "Strict lockdown", "Moderate lockdown", "Strict lockdown"),
                   stringsAsFactors = FALSE) %>%
  mutate(median_x = start + floor((end-start)/2))


p <- ggplot() +
  geom_rect(data=covid_lvl, aes(NULL, NULL, xmin=start, xmax=end, fill=level, 
                                ymin= -Inf, ymax=Inf), alpha=0.1) +
  labs(fill="Covid-19 lockdown", linetype="Land Use Zones", colour="Land Use Zones",
       x="Date", y="Debris count per survey cycle") +
  # geom_point(data=item_per_cycle, aes(date, cycle_sum, color=LUZ)) +
  geom_line(data=item_per_cycle, aes(date, cycle_sum, linetype=LUZ, color=LUZ)) +
  theme(axis.text.x=element_text(angle=45, vjust=0.75, hjust=0.8)) +
  facet_wrap(~item, scales="free_y") 
p

#reference: https://plotly.com/ggplot2/geom_rect/ tutorial for geom_rect background
```

```{r data-mod, warning=FALSE, message=FALSE}
#aggregate data
mod <- df %>%
  group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
  summarise(sum=sum(sum)) %>%
  ungroup() %>%
  filter(cycle %in% paste0("C",1:7)) %>%
  mutate(LGA = as.factor(LGA),
         LUZ = as.factor(LUZ),
         covid = as.factor(covid),
         cycle = as.factor(cycle))
       
#create model
m  <- glmmTMB(sum ~ #Debris count per survey event
                LUZ * covid + #predicted by land use effected by covid
                 (1|LGA/asset_id) + (1|cycle), #suburb random effect
               family=nbinom2(), #negative binomial to deal with count data and zeros
               data = mod)

#create predictor df
nd <- expand.grid(covid = unique(mod$covid),
                  LUZ = unique(mod$LUZ),
                  LGA = NA,
                  asset_id = NA,
                  cycle = NA)

#predict mean values of response variable
pred <- predict(object=m,
                newdata=nd,
                se.fit=T,
                re.form=NA,
                type="response")

#create standard error for graphing
nd$Total <- pred$fit
nd$SE_upper <- pred$fit + pred$se.fit
nd$SE_lower <- pred$fit - pred$se.fit

# New facet label names for covid variable
nd$covid <- factor(nd$covid, levels = c("1", "2", "3"),
                  labels = c("No lockdown", "Moderate lockdown", "Strict lockdown"))

#create plot
p <- ggplot(nd, aes(y=Total, x=LUZ, fill=covid)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  labs(title="Debris count (every 6 weeks)",
       subtitle="By land use zone and covid restriction",
       x="", y="Total debris items per asset", tag="") 

p

unique(df$item)
```

```{r data-mod-top5, warning=FALSE, message=FALSE}
# Function loop: each item

#Top 4 plus OH&S
txt<- df %>%
  filter(item %in% c("Plastic shards", 
                     "Plastic chips",
                     "Plastic resin pellet")) %>% 
  distinct(item)%>%
  pull(item) %>% 
  droplevels()

# Purrr
library(purrr)

pred_df = purrr::map_df(txt, function(x){
  
  temp_df = df %>% 
    filter(item == paste0(x)) %>%
    group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
    summarise(sum=sum(sum)) %>%
    ungroup() %>%
    filter(cycle %in% paste0("C",1:7)) %>%
    mutate(LGA = as.factor(LGA),
           LUZ = as.factor(fct_relevel(LUZ, "CBD", "Shopping Centre", "Public Transport Terminal", "Industrial Precinct")),
           covid = as.factor(covid),
           cycle = droplevels(as.factor(cycle)),
           item = x)
 
 #create model
 m_temp  <- glmmTMB(sum ~ #Debris count per survey event
                   LUZ * covid + #predicted by land use effected by covid
                   (1|LGA/asset_id) + (1|cycle), #suburb random effect
                   family=nbinom2(), #negative binomial to deal with count data and zeros
                   data = temp_df)

 nd_temp <- expand.grid(covid = unique(temp_df$covid),
                       LUZ = unique(temp_df$LUZ),
                       LGA = NA,
                       asset_id = NA,
                       cycle = NA)
 
 #predict function uses the model and the new df to predict mean values of the response variable.  It predicts a value for each row in the new df.
 pred_temp <- predict(object=m_temp,
                     newdata=nd_temp,
                     se.fit=T,
                     re.form=NA,
                     type="response")
 
 #creating standard error for graphing
 nd_temp$Total <- pred_temp$fit
 nd_temp$SE_upper <- pred_temp$fit + pred_temp$se.fit
 nd_temp$SE_lower <- pred_temp$fit - pred_temp$se.fit
 nd_temp$item = x
 
 return(nd_temp)
 
 })

#create columns for predictions by LUZ rather than by asset
pred_df <- pred_df %>%
  mutate(luz_tot = Total*5,
         LUZ_SE_upper = SE_upper*5,
         LUZ_SE_lower = SE_lower*5)

# New facet label names for covid variable
pred_df$covid <- factor(pred_df$covid, levels = c("1", "2", "3"),
                  labels = c("No lockdown", "Moderate lockdown", "Strict lockdown"))

 #create plot
p_all <- ggplot(pred_df, aes(y=luz_tot, x=LUZ, fill=covid)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=LUZ_SE_lower, ymax=LUZ_SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  labs(title="Debris count (every 6 weeks per LGA)",
       subtitle="By covid restriction",
       x="", y="Total debris items per land use zone", tag="") +
  facet_wrap(~item, scales="free_y") +
  guides(x =  guide_axis(angle = 45)) 

p_all
 
```