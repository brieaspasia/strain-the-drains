---
title: "Results-Figs"
author: "Brie Sherow"
date: "05/04/2021"
output: 
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    df_print: paged
  pdf_document:
    toc: yes
---

```{r setup, warning=FALSE, message=FALSE, results='hide', include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, warning=FALSE, message=FALSE, results='hide', include=FALSE}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(tidyr) #long & wide formats
library(reshape2) #melt function for wide and long formats
library(stats) #R stats functions
library(broom) #create summaries from stats objects
library(car) #lm regression
library(MASS) #stats
library(lme4) #glmer function
library(DHARMa) #testing model diagnostics
library(glmmTMB) #fit zero-inflated negative binomial
library(lattice) #fourth corner heatmap
library(corrplot) #co-occurrence matrix
library(gclus) #co-occurrence matrix
library(broom.mixed) #regression tables
library(vegan) #ordination
library(emmeans)
library(ComplexHeatmap)
library(RColorBrewer)
library(heatmaply)
library(cowplot) #minimal backgrounds for ggplot

```

```{r create-df, warning=FALSE, message=FALSE, results='hide', include=FALSE}
#create survey count  

        #load item counts
        item <- read.csv(file="Data/2101_item.csv", 
                         header=T, sep=",") 

#remove duplicate entries
        item <- unique(item[!duplicated(item),])

        #load item labels
        item_label <- read.csv(file="Data/item_label.csv", 
                         header=T, sep=",") 
        
        #load events
        event <- read.csv(file="Data/2101_event.csv", 
                         header=T, sep=",") 
        
        #join event info to item count
        survey_count <- left_join(item, event, by="event_id")
        
        survey_count <- survey_count %>%
          dplyr::select(-event.tot, -event.wt, -vol, -hr, -event_date, -note) %>%
          filter(item!="Pollution Rating") 

        #summarise duplicate survey entries (this will lose one set of notes....)
        item_merge <- survey_count %>%
          group_by(event_id, item) %>%
          summarise(sum=sum(total)) %>%
         ungroup()

        #join survey count to the merged summaries
        survey_count <- item_merge %>%
          left_join(survey_count, by=c("event_id"="event_id", "item"="item")) %>%
          dplyr::select(-total) %>%
          unique()
        
#create abundance data with all possible debris items and zero values

      # #count of items per unique event
      # event_count <- survey_count %>%
      #   group_by(event_id, item) %>%
      #   summarise(sum=sum(sum)) %>%
      #   ungroup()

      #load AMDI code\
      AMDI_code <- read.csv(file="Data/200101_AMDI_code.csv", 
                       header=T, sep=",") 
      
      #create full list of possible items
      AMDI <- AMDI_code %>%
        filter(item_code_id != "LSTD1") %>% #remove pollution rating / microplastics
        dplyr::select(item.ex, mat) #column of all possible item types
      
      
      #create a df of all possible items at all survey events, complete with zeros
      abund <- full_join(AMDI, survey_count, by=c("item.ex" = "item"))
      
      #data long to wide
      abund_wide <- abund %>%
        spread(item.ex, sum) %>%
        dplyr::select(-Asset.ID, -Cycle, -covid, -date, -mat)
      
      #replace na values with 0
      abund_wide[is.na(abund_wide)] <- 0
        
      #transform back to long but now with the full items list and zero data
      abund_long <- melt(abund_wide, id.vars="event_id")
      
      #remove the zero event ID (how did that get there?)
      abund_long <- abund_long[abund_long$event_id != 0, ]

#join abundance data to survey notes and other columns
      df <- left_join(abund_long, event, by="event_id")
      
        #load sites
          site <- read.csv(file="Data/200619_site.csv", 
                           header=T, sep=",") 
      
            #join LGA and luz to df
          df <- left_join(df, site, by = "Asset.ID")
          
          #classify items correctly      
           df <- df %>%
        dplyr::select(-event_date, -event.tot, -event.wt, -vol, -hr, 
                      -Site, -Latitude, -Longitude) %>% #remove duplicate columns
        rename(item=variable, #rename columns
               sum=value,
               asset_id = Asset.ID,
               cycle=Cycle,
               LUZ = Land.use.zone) %>% 
        mutate(asset_id=as.factor(asset_id), #classify columns correctly  
             item=as.factor(item),
             LGA=as.factor(LGA),
             LUZ=as.factor(LUZ),
             event_id=as.factor(event_id),
             cycle=as.factor(cycle),
             date=dmy(date)
             )

#resolve duplicates in MC01, C5    
          dup <- df %>% 
            group_by(asset_id, cycle, item) %>% #reconcile duplicates in MC01 Cycle 5
            summarise(sum=sum(sum)) %>%
            ungroup()
           
      # #check difference
      #      subsetdf <- df %>%
      #        dplyr::select(Asset.ID, Cycle, item, sum)
      #      
      #      setdiff(subsetdf, dup)
           
      #join C5 correction to df
      df <- dup %>% left_join(df, by=c("asset_id"="asset_id", 
                                       "cycle"="cycle", "item"="item")) %>%
        dplyr::select(-sum.y) %>%
        filter(event_id != "23097") %>%
        rename(sum = sum.x) %>%
        distinct()
      
      item_labelDF <- df %>%
        distinct(item)
      
      df <- df %>%
        left_join(item_label, by=c("item" = "item.type")) %>%
        mutate(item = A3) %>%
        dplyr::select(-A3)
      
#classify columns correctly    
      df <- df %>%
      mutate(item=as.factor(item),
             covid=as.factor(covid),
             material=as.factor(material))

#Combine C8 and C9    
     #isolate C8
    C8 <- df %>%
      filter(cycle == "C8")
    
    #isolate C9
    C9 <- df %>%
      filter(cycle == "C9")
    
    #join C8 and C9 by unique drain and item to capture double surveys
    t <- left_join(C9, C8, by=c("asset_id"="asset_id", "item" = "item"))
    t$sum.y[is.na(t$sum.y)] <- 0 #change na to 0
    
    t <- t %>%
      mutate(combined_sum = sum.y + sum.x) %>% #add C8 and C9 together
      dplyr::select(event_id.x, item, combined_sum)
    
    df <- df %>% 
      left_join(t, by = c("event_id"="event_id.x", "item"="item")) %>%
      filter(cycle != "C8") %>%
      mutate(combined_sum = replace_na(combined_sum, 0),
              sum2 = ifelse(cycle != "C9", sum, 0),
              final_sum = sum2 + combined_sum) %>%
      dplyr::select(-sum2, -sum, -combined_sum) %>%
      rename(sum = final_sum)

# #overview numbers
#     t <- df %>%
#       group_by(material) %>%
#       summarise(total=sum(sum)) %>%
#       mutate(pct = total/87406 * 100)
```
# Percentage of items by land use
We'd discussed recreating this with errorbars, however I'm not sure how that would work as these values represent the sum total of items in each of these land uses?  We also discussed moving this to supplementary data, however I think it's actually a really important part of the story. While Covid impact may be a hot topic currently, I don't want the land use results to get lost in the Covid hype, especially because I haven't found any other papers about land use and stormwater debris. Also, the differences between land use are likely the most relevant part of this data in terms of implications for debris management efforts. 
```{r heatmap-item-top15, warning=FALSE, message=FALSE}

top10 <- df %>%
  filter(cycle %in% c("C1", "C2", "C3", "C4")) %>%
  filter(item != "Metal scrap") %>% #removing outlier entry
  group_by(item) %>%
  summarise(total=sum(sum)) %>%
  arrange(desc(total)) %>%
  top_n(10) %>%
  dplyr::select(item)

top10 <- as.vector(unlist(top10))

top_LUZ <- df %>%
  filter(cycle %in% c("C1", "C2", "C3", "C4")) %>%
  group_by(LUZ) %>%
  mutate(total_LUZ=sum(sum)) %>%
  ungroup() %>%
  group_by(LUZ, item) %>%
  mutate(total_itemLUZ = sum(sum)) %>%
  ungroup() %>%
  mutate(pct = (total_itemLUZ/total_LUZ)*100) %>%
  filter(item %in% top10) %>%
  dplyr::select(item, LUZ, pct) %>%
  unique() %>%
  spread(item, pct) %>%
  column_to_rownames(var="LUZ") 

mat <- data.matrix(top_LUZ) #matrix for heatmap
mat <- round(mat,0)
mat2 = ifelse(mat <= 0.99,"<1",as.character(round(mat,2))) #matrix for labels


col_ha <- HeatmapAnnotation(Region = anno_text(colnames(mat), location = 1, rot = 60, 
                              just = "right"))

Heatmap(log10(mat+0.1), 
        name = "Debris count (percentage per land use zone)", 
        heatmap_legend_param  = list(color_bar = "continuous", at = c(-2.6,3.5),
                      title = "Debris counts (% total)",labels = c("Low", "High"),
                      grid_width = unit(0.8, "cm"),
                      legend_height = unit(5, "cm"),
                      title_position = "leftcenter-rot"), 
        col= colorRampPalette(brewer.pal(8, "PRGn"))(25),
        row_dend_reorder = TRUE, 
        row_order = sort(rownames(mat)),
        show_column_dend = FALSE,
        show_row_dend = FALSE,
        bottom_annotation = col_ha,
        show_row_names = TRUE,
        row_names_side = "left",
        show_column_names = FALSE,
        border = TRUE,
        column_title = "Percentage of top 10 debris items per land use zone",
        #percentage label
        cell_fun = function(j, i, x, y, width, height, fill) {
        grid.text(sprintf("%s", mat2[i, j],"%"), x, y, gp = gpar(fontsize = 10))},
        )

```


## Timeline of debris item count


Top 15 items + OH&S through Covid-19 lockdowns.
```{r avg-items-per-lockdown, warning=FALSE, message=FALSE}
#find top 15 items
top15 <- df %>%
  filter(item != "Metal scrap") %>% #removing outlier entry
  group_by(item) %>%
  summarise(sum=sum(sum)) %>%
  arrange(desc(sum)) %>%
  top_n(15, sum)
  
#create vector from top 15 items
top15 <- top15$item 
top15 <- unlist(top15)

pol_items <- df %>%
  filter(item == "OH & S" | item=="Aluminium cans" | item=="Beer bottles (and similar)" | item == "Foam take-away")

#create vector from policy items
pol_items <- pol_items$item 
pol_items <- unlist(pol_items)

item_per_cycle <- df %>%
  filter(item %in% top15 | item %in% pol_items) %>%
  group_by(date, covid, LUZ, item) %>%
  summarise(cycle_sum = sum(sum))

covid_lvl <- data.frame(name = c("1", "2"),
                   start = as.Date(c("2019-10-29", "2020-03-15")),
                   end = as.Date(c("2020-03-15", "2020-10-17")),
                   level = c("Pre-Covid", "During Covid"),
                   stringsAsFactors = FALSE) %>%
  mutate(median_x = start + floor((end-start)/2))


p <- ggplot() +
  geom_rect(data=covid_lvl, aes(NULL, NULL, xmin=start, xmax=end, fill=level, 
                                ymin= -Inf, ymax=Inf), alpha=0.1) +
  labs(fill="Covid-19 lockdown", linetype="Land Use Zones", colour="Land Use Zones",
       x="Date", y="Debris count per survey cycle") +
  # geom_point(data=item_per_cycle, aes(date, cycle_sum, color=LUZ)) +
  geom_line(data=item_per_cycle, aes(date, cycle_sum, linetype=LUZ, color=LUZ)) +
  theme(axis.text.x=element_text(angle=45, vjust=0.75, hjust=0.8)) +
  facet_wrap(~item, scales="free_y") 
p

#reference: https://plotly.com/ggplot2/geom_rect/ tutorial for geom_rect background
```



##GLMM and predictions


I had a note to recreate this as a line graph through time, but that would necessitate changing the model and adding cycle or date as a fixed effect, which seems like I shouldn't do.  I tried several versions of that model and of a line graph, but none really made sense...
```{r data-mod, warning=FALSE, message=FALSE}
#aggregate data
mod <- df %>%
  group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
  summarise(sum=sum(sum)) %>%
  ungroup() %>%
  # filter(cycle %in% paste0("C",1:7)) %>%
  mutate(LGA = as.factor(LGA),
         LUZ = as.factor(fct_relevel(LUZ, "CBD", "Shopping Centre", "Public Transport Terminal", "Industrial Precinct")),
         covid = as.factor(covid),
         cycle = as.factor(cycle))
       
#create model
m  <- glmmTMB(sum ~ #Debris count per survey event
                LUZ * covid + #predicted by land use effected by covid
                 (1|LGA/asset_id) + (1|cycle), #suburb random effect
               family=nbinom2(), #negative binomial to deal with count data and zeros
               data = mod)

#create predictor df
nd <- expand.grid(covid = unique(mod$covid),
                  LUZ = unique(mod$LUZ),
                  LGA = NA,
                  asset_id = NA,
                  cycle = NA)

#predict mean values of response variable
pred <- predict(object=m,
                newdata=nd,
                se.fit=T,
                re.form=NA)

#create standard error for graphing
nd$Total <- exp(pred$fit)
nd$SE_upper <- exp(pred$fit + pred$se.fit)
nd$SE_lower <- exp(pred$fit - pred$se.fit)

# New facet label names for covid variable
nd$covid <- factor(nd$covid, levels = c("1", "2"),
                  labels = c("Pre-Covid", "During Covid"))

#create plot
p <- ggplot(nd, aes(y=Total, x=LUZ, fill=covid)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  labs(title="Debris count per asset (every 6 weeks)",
       subtitle="By land use zone and covid restriction",
       x="", y="Total debris items per asset", tag="") 

p
```

# GLMM for top four items and OH&S


The above graph shows total debris count per asset every 6 weeks.  Because of lower numbers, here I've shown total debris count per LGA land use zone every 6 weeks. 
```{r data-mod-top5, warning=FALSE, message=FALSE}
# Function loop: each item

#Top 4 plus OH&S
top5_txt<- df %>%
  filter(item %in% c("Cigarette butts", 
                     "Plastic packaging (food)",
                     "Plastic wrap (non-food)",
                     "Soft plastic remnants",
                     "OH & S")) %>% 
  distinct(item)%>%
  pull(item) %>% 
  droplevels()
 
# Purrr
library(purrr)

pred_df = purrr::map_df(top5_txt, function(x){
  
  temp_df = df %>% 
    filter(item == paste0(x)) %>%
    group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
    summarise(sum=sum(sum)) %>%
    ungroup() %>%
    # filter(cycle %in% paste0("C",1:7)) %>%
    mutate(LGA = as.factor(LGA),
           LUZ = as.factor(fct_relevel(LUZ, "CBD", "Shopping Centre", "Public Transport Terminal", "Industrial Precinct")),
           covid = as.factor(covid),
           cycle = droplevels(as.factor(cycle)),
           item = x)
 
 #create model
 m_temp  <- glmmTMB(sum ~ #Debris count per survey event
                   LUZ * covid + #predicted by land use effected by covid
                   (1|LGA/asset_id) + (1|cycle), #suburb random effect
                   family=nbinom2(), #negative binomial to deal with count data and zeros
                   data = temp_df)

 nd_temp <- expand.grid(covid = unique(temp_df$covid),
                       LUZ = unique(temp_df$LUZ),
                       LGA = NA,
                       asset_id = NA,
                       cycle = NA)
 
 #predict function uses the model and the new df to predict mean values of the response variable.  It predicts a value for each row in the new df.
 pred_temp <- predict(object=m_temp,
                     newdata=nd_temp,
                     se.fit=T,
                     re.form=NA,
                     type="response")
 
 #creating standard error for graphing
 nd_temp$Total <- pred_temp$fit
 nd_temp$SE_upper <- pred_temp$fit + pred_temp$se.fit
 nd_temp$SE_lower <- pred_temp$fit - pred_temp$se.fit
 nd_temp$item = x
 
 return(nd_temp)
 
 })

# New facet label names for covid variable
pred_df$covid <- factor(pred_df$covid, levels = c("1", "2"),
                  labels = c("Pre-Covid", "During Covid"))

 #create plot
p_all <- ggplot(pred_df, aes(y=Total, x=LUZ, fill=covid)) + 
  geom_bar(position="dodge", stat="identity") +
  geom_errorbar(aes(ymin=SE_lower, ymax=SE_upper, width=0.2), position=position_dodge(width=0.90)) +
  labs(title="Debris count per asset (every 6 weeks)",
       subtitle="By covid restriction",
       x="", y="Total debris items per land use zone", tag="") +
  facet_wrap(~item, scales="free_y") +
  guides(x =  guide_axis(angle = 45)) 

p_all
 
```

# MDS plot


I've found that the MDS plot changes a lot depending on what variables I use to aggregate.  Here I've used all the variables from the model except asset_ID, as the unique assets created a lot of background noise.
```{r MDS-LGA-top15, warning=FALSE, message=FALSE, include=FALSE, results='hide'}
#find top 20 items
top15 <- df %>%
  group_by(item) %>%
  summarise(sum=sum(sum)) %>%
  arrange(desc(sum)) %>%
  top_n(15, sum)
  
#create vector from top 20 items
top15 <- top15$item 
top15 <- unlist(top15)


df_top15 <- df %>%
  filter(item %in% top15)

#create abundance long format
 abund_long <- df_top15 %>%
    group_by(LGA, LUZ, covid, item) %>% 
    summarise(sum=sum(sum)) %>% #total of each item type per survey event
  ungroup()

#convert to data wide
  abund <- spread(abund_long, item, sum) 

  
  com <- abund[4:18]
  
  #removing debris items that are zero across all surveys
  com <- com[, which(colSums(com) != 0)]
  
  ord <- metaMDS(com)
  
  data.scores <- as.data.frame(scores(ord)) #create df of ord points
  data.scores$LUZ <- abund$LUZ
  data.scores$covid <- abund$covid
  data.scores <- data.scores %>%
    mutate(covid = as.factor(covid),
           LUZ = as.factor(LUZ))
  
  species.scores <- as.data.frame(scores(ord, "species"))
  species.scores$item <- rownames(species.scores) #create item id column
  
  
#Hull data LUZ
CBD <- data.scores[data.scores$LUZ == "CBD", ][chull(data.scores[data.scores$LUZ ==
    "CBD", c("NMDS1", "NMDS2")]), ]  # hull values for CBD
Transport <- data.scores[data.scores$LUZ == "Public Transport Terminal", ][chull(data.scores[data.scores$LUZ ==
    "Public Transport Terminal", c("NMDS1", "NMDS2")]), ]  # hull values for Transport
Indus <- data.scores[data.scores$LUZ == "Industrial Precinct", ][chull(data.scores[data.scores$LUZ == "Industrial Precinct", c("NMDS1", "NMDS2")]), ]  # hull values for Industry
Shop <- data.scores[data.scores$LUZ == "Shopping Centre", ][chull(data.scores[data.scores$LUZ ==
    "Shopping Centre", c("NMDS1", "NMDS2")]), ]  # hull values for shopping

#create polygons
LUZ.hull.data <- rbind(CBD, Transport, Indus, Shop)  #combine groups
LUZ.hull.data

#Hull data covid
covid1 <- data.scores[data.scores$covid == "1", ][chull(data.scores[data.scores$covid ==
    "1", c("NMDS1", "NMDS2")]), ]  # hull values for Pre-Covid
covid2 <- data.scores[data.scores$covid == "2", ][chull(data.scores[data.scores$covid ==
    "2", c("NMDS1", "NMDS2")]), ]  # hull values for During Covid

#create polygons
cov.hull.data <- rbind(covid1,covid2)  #combine groups
cov.hull.data

# New facet label names for covid variable
data.scores$covid <- factor(data.scores$covid, levels = c("1", "2"),
                  labels = c("Pre-Covid", "During Covid"))
```

```{r MDS-plot, warning=FALSE, message=FALSE}
#MDS plot
ggplot() +
  geom_polygon(data=LUZ.hull.data,aes(x=NMDS1,y=NMDS2,fill=LUZ,group=LUZ),alpha=0.1) +
  geom_text(data=species.scores,aes(x=NMDS1,y=NMDS2, label=item)) +
  geom_point(data=data.scores, 
             aes(x=NMDS1, y=NMDS2, colour=LUZ, shape=covid), alpha=0.8) + 
  coord_equal() +
  theme_bw()

# ggplot() +
#   geom_polygon(data=cov.hull.data,
#                aes(x=NMDS1,y=NMDS2,fill=covid,group=covid),alpha=0.1) +
#   geom_text(data=species.scores,aes(x=NMDS1,y=NMDS2, label=item)) +
#   geom_point(data=data.scores, 
#              aes(x=NMDS1, y=NMDS2, colour=covid, shape=LUZ), alpha=0.8) + 
#   coord_equal() +
#   theme_bw()
```

# Testing community data


```{r adonis-pairwise, warning=FALSE, message=FALSE}

#Both land use and covid have significant scores, but there is not a significant interaction between them
df.adonis <- adonis(com ~ data.scores$LUZ*data.scores$covid, permutations=999, method="bray")
df.adonis

#testing land use dispersion
df.dis <- vegdist(com, method = "bray") # make a distance matrix
df.betadisper.luz <- betadisper(df.dis, data.scores$LUZ) # test dispersion
df.betadisper.luz
permutest(df.betadisper.luz) #dispersion not significant

#testing covid dispersion
df.dis <- vegdist(com, method = "bray") # make a distance matrix
df.betadisper.cov <- betadisper(df.dis, data.scores$covid) # test dispersion
df.betadisper.cov
permutest(df.betadisper.cov) #dispersion not significant
```