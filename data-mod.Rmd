---
title: "drains-data-mod"
author: "Brie Sherow"
date: "06/02/2021"
output: html_document
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    df_print: paged
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
getwd()
```

```{r libraries}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(kableExtra) #table layouts
library(tidyr) #long & wide formats
library(reshape2) #melt function for wide and long formats
library(stats) #R stats functions
library(broom) #create summaries from stats objects
library(car) #lm regression
library(MASS) #stats
library(lme4) #glmer function
library(DHARMa) #testing model diagnostics
library(glmmTMB) #fit zero-inflated negative binomial
library(lattice) #fourth corner heatmap
library(corrplot) #co-occurrence matrix
library(gclus) #co-occurrence matrix
library(broom.mixed) #regression tables
library(vegan) #ordination
library(emmeans)
```

```{r create-df}

#create survey count  

        #load item counts
        item <- read.csv(file="Data/2101_item.csv", 
                         header=T, sep=",") 
        
        #load events
        event <- read.csv(file="Data/2101_event.csv", 
                         header=T, sep=",") 
        
        #join event info to item count
        survey_count <- left_join(item, event, by="event_id")
        
        survey_count <- survey_count %>%
          dplyr::select(-event.tot, -event.wt, -vol, -hr, -note) %>%
          filter(item!="Pollution Rating") %>%
          mutate(event_item = paste(event_id, item, sep=" "))

        #summarise duplicate survey entries (this will lose one set of notes....)
        item_merge <- survey_count %>%
          group_by(event_item) %>%
          summarise(sum=sum(total)) %>%
         ungroup()

        #join survey count to the merged summaries
        survey_count <- item_merge %>%
          left_join(survey_count, by="event_item") %>%
          dplyr::select(-total) %>%
          unique()
        
#create abundance data with all possible debris items and zero values

      #count of items per unique event
      event_count <- survey_count %>%
        group_by(event_id, item) %>%
        summarise(sum=sum(sum)) %>%
        ungroup()

      #load AMDI code\
      AMDI_code <- read.csv(file="Data/200101_AMDI_code.csv", 
                       header=T, sep=",") 
      
      #create full list of possible items
      AMDI <- AMDI_code %>%
        filter(item_code_id != "LSTD1") %>% #remove pollution rating / microplastics
        dplyr::select(item.ex) #column of all possible item types
      
      
      #create a df of all possible items at all survey events, complete with zeros
      abund <- full_join(AMDI, event_count, by=c("item.ex" = "item"))
      
      #remove empty row
      abund <- abund[-11613, ]
      
      #data long to wide
      abund_wide <- spread(abund, item.ex, sum)
      
      #replace na values with 0
      abund_wide[is.na(abund_wide)] <- 0
        
      #transform back to long but now with the full items list and zero data
      abund_long <- melt(abund_wide, id.vars="event_id")
      
      #remove the zero event ID (how did that get there?)
      abund_long <- abund_long[abund_long$event_id != 0, ]
      
      #create event_item column for joining
      abund_long <- abund_long %>%
      mutate(event_item = paste(event_id, variable, sep=" "))

#join abundance data to survey notes and other columns
  df <- left_join(abund_long, survey_count, by="event_item") 
  
  df <- df %>%
    dplyr::select(-event_item, -event_id.y, -item, -sum) %>% #remove duplicate columns
    rename(event_id=event_id.x,
           item=variable,
           sum=value) %>% #rename columns
    arrange(event_id, Asset.ID) %>% #arrange by event so that missing values are aligned
    fill(Asset.ID, Cycle, date, covid) #fill in missing values to match survey data

  #clean up column classifications
  
  #reclassify columns to factor
    names <- c("event_id", "Asset.ID", "Cycle")
  
    df[,names] <- lapply(df[,names], factor)
  
  #reclassify date
    df$date <- dmy(df$date)

#join land use zone and LGA
    
    #load sites
        site <- read.csv(file="Data/200619_site.csv", 
                         header=T, sep=",") 
        
    #join LGA and luz to df
        df <- left_join(df, site, by = "Asset.ID")
        
    #remove unecessary columns
        df <- df %>%
          dplyr::select(-Site, -Latitude, -Longitude) 
     
#resolve duplicates in MC01, C5    
        dup <- df %>% 
          group_by(Asset.ID, Cycle, item) %>% #reconcile duplicates in MC01 Cycle 5
          summarise(sum=sum(sum)) %>%
          ungroup() %>%
          mutate(join = paste(Asset.ID, Cycle, item, sep=" "))
         
    # #check difference
    #      subsetdf <- df %>%
    #        dplyr::select(Asset.ID, Cycle, item, sum)
    #      
    #      setdiff(subsetdf, dup)
         
    #join C5 correction to df
         df <- df %>%
           mutate(join = paste(Asset.ID, Cycle, item, sep=" "))
         
    df <- dup %>% left_join(df, by="join") %>%
      dplyr::select(-join, -item.y, -sum.y, -Asset.ID.y, -Cycle.y) %>%
      filter(event_id != "23097") %>%
      rename(
          asset_id = Asset.ID.x, 
          cycle = Cycle.x,
          item = item.x,
          sum = sum.x,
          LUZ = Land.use.zone,
      ) %>%
      distinct()
        
```


```{r day-diff}

#find days since last survey at each asset
diff <- df %>%
  distinct(event_id, .keep_all = T) %>%
  select(-item,-sum) %>%
  group_by(asset_id) %>% #looking at each event
  arrange(date) %>%
  mutate(days = date - lag(date)) %>% #days since last survey event
  filter(days != "NA") %>% #remove first survey date
  ungroup()

diff_red <- diff %>% select(event_id, asset_id, days)

df <- df %>%
  left_join(diff_red, by="event_id") %>%
  dplyr::select(-asset_id.y) %>%
  rename(asset_id = asset_id.x)

#calculate diff since last event, then factor in the sum per item

str(df)

df$days <- as.numeric(df$days)

t <- df %>%
  mutate(change = (sum/days))

# https://rdrr.io/cran/DataCombine/man/PercChange.html
```

```{r LUZ-plus-Covid}

#create df to use for models
mod <- df %>%
  group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
  summarise(sum=sum(sum)) %>%
  ungroup() %>%
  filter(cycle %in% c("C1", "C2", "C3", "C4", "C5", "C6", "C7")) %>%
  mutate(LGA = as.factor(LGA),
         LUZ = as.factor(LUZ),
         cycle = as.factor(cycle))

#model
m  <- glmmTMB(sum ~ #Debris count per survey event
                LUZ + #predicted by land use zone
                covid + #predicted by covid lockdown
                 (1|LGA) + (1|cycle), #suburb random effect
               family=nbinom1(), #negative binomial to deal with count data and zeros
               data = mod)

summary(m)
coef(m)
```
```{r dharma-add}

simulationOutput <- simulateResiduals(fittedModel = m, plot=T)
  
plotResiduals(simulationOutput)
testUniformity(simulationOutput) #tests if the overall distribution conforms to expectations
# testOutliers(simulationOutput) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput) #tests if the simulated dispersion is equal to the observed dispersion
#testQuantiles(simulationOutput) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput) #tests if there are more zeros than expected
```
```{r LUZ-effect-Covid}
mod <- df %>%
  group_by(event_id, asset_id, cycle, date, covid, LGA, LUZ) %>% #relevant variables
  summarise(sum=sum(sum)) %>%
  ungroup() %>%
  filter(cycle %in% c("C1", "C2", "C3", "C4", "C5", "C6", "C7")) %>%
  mutate(LGA = as.factor(LGA),
         LUZ = as.factor(LUZ),
         covid = as.factor(covid),
         cycle = as.factor(cycle))


m2  <- glmmTMB(sum ~ #Debris count per survey event
                LUZ * covid + #predicted by land use effected by covid
                 (1|LGA/asset_id) + (1|cycle), #suburb random effect
               family=nbinom2(), #negative binomial to deal with count data and zeros
               data = mod)

drop1(m2, test="Chisq")

str(mod)

emmeans(m2, ~covid|LUZ)
emmeans(m2, pairwise~covid|LUZ, type="response")

summary(m2)
coef(m2)

ggplot(data=mod, aes(x=covid, y=sum)) +
  geom_boxplot() +
       facet_wrap(~LUZ)
```
```{r dharma-effect}
simulationOutput2 <- simulateResiduals(fittedModel = m2, plot=T)
  
plotResiduals(simulationOutput2)
testUniformity(simulationOutput2) #tests if the overall distribution conforms to expectations
# testOutliers(simulationOutput) #tests if there are more simulation outliers than expected
testDispersion(simulationOutput2) #tests if the simulated dispersion is equal to the observed dispersion
#testQuantiles(simulationOutput) #fits a quantile regression or residuals against a predictor (default predicted value), and tests of this conforms to the expected quantile
testZeroInflation(simulationOutput2) #tests if there are more zeros than expected
```

