---
title: "drains-data-mod"
author: "Brie Sherow"
date: "06/02/2021"
output: html_document
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    df_print: paged
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
getwd()
```

```{r libraries}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(kableExtra) #table layouts
library(tidyr) #long & wide formats
library(reshape2) #melt function for wide and long formats
```

```{r create-df}

#create survey count  ****Why is this not picking up cycle 9****

        #load item counts
        item <- read.csv(file="Data/2101_item.csv", 
                         header=T, sep=",") 
        
        #load events
        event <- read.csv(file="Data/2101_event.csv", 
                         header=T, sep=",") 
        
        #join event info to item count
        survey_count <- left_join(item, event, by="event_id")
        
        survey_count <- survey_count %>%
          dplyr::select(-event.tot, -event.wt, -vol, -hr, -note) %>%
          filter(item!="Pollution Rating") %>%
          mutate(event_item = paste(event_id, item, sep=" "))

        #summarise duplicate survey entries (this will lose one set of notes....)
        item_merge <- survey_count %>%
          group_by(event_item) %>%
          summarise(sum=sum(total)) %>%
         ungroup()

        #join survey count to the merged summaries
        survey_count <- item_merge %>%
          left_join(survey_count, by="event_item") %>%
          dplyr::select(-total) %>%
          unique()
        
#create abundance data with all possible debris items and zero values

      #count of items per unique event ID
      event_count <- survey_count %>%
        group_by(event_id, item) %>%
        summarise(sum=sum(sum))

      #load AMDI code\
      AMDI_code <- read.csv(file="Data/200101_AMDI_code.csv", 
                       header=T, sep=",") 
      
      #create full list of possible items
      AMDI <- AMDI_code %>%
        filter(item_code_id != "LSTD1") %>% #remove pollution rating / microplastics
        dplyr::select(item.ex) #column of all possible item types
      
      
      #create a df of all possible items at all survey events, complete with zeros
      abund <- full_join(AMDI, event_count, by=c("item.ex" = "item"))
      
      #remove empty row
      abund <- abund[-11613, ]
      
      #data long to wide
      abund_wide <- spread(abund, item.ex, sum)
      
      #replace na values with 0
      abund_wide[is.na(abund_wide)] <- 0
        
      #transform back to long but now with the full items list and zero data
      abund_long <- melt(abund_wide, id.vars="event_id")
      
      #remove the zero event ID (how did that get there?)
      abund_long <- abund_long[abund_long$event_id != 0, ]
      
      #create event_item column for joining
      abund_long <- abund_long %>%
      mutate(event_item = paste(event_id, variable, sep=" "))

#join abundance data to survey notes and other columns
  df <- left_join(abund_long, survey_count, by="event_item") 
  
  df <- df %>%
    dplyr::select(-event_item, -event_id.y, -item, -sum) %>% #remove duplicate columns
    rename(event_id=event_id.x,
           item=variable,
           sum=value) %>% #rename columns
    arrange(event_id, Asset.ID) %>% #arrange by event so that missing values are aligned
    fill(Asset.ID, Cycle, date, covid) #fill in missing values to match survey data

#clean up column classifications
  
  #reclassify columns to factor
    names <- c("event_id", "Asset.ID", "Cycle")
  
    df[,names] <- lapply(df[,names], factor)
  
  #reclassify date
    df$date <- dmy(df$date)

#join land use zone and LGA
    
    #load sites
        site <- read.csv(file="Data/200619_site.csv", 
                         header=T, sep=",") 
        
    #join LGA and luz to df
        df <- left_join(df, site, by = "Asset.ID")
        
    #remove unecessary columns
        df <- df %>%
          dplyr::select(-Site, -Latitude, -Longitude)
```


```{r day-diff}

#find days since last survey at each asset
t <- df %>%
  group_by(Asset.ID, item) %>% #looking at each item at each drain
  mutate(Days = date - lag(date)) %>% #days since last survey event
  filter(Days != "NA") %>% #remove first survey date
  ungroup()

#some assets are showing negative days in C8 - ex. DC13

```

