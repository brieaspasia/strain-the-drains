---
title: "drains-gllvm"
author: "Brie Sherow"
date: "12/02/2021"
output: 
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    df_print: paged
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load-libraries}
library(ggplot2) #graphing
library(ggthemes) #graphing templates
library(hrbrthemes) #graphing templates
library(lubridate) #date manipulation
library(forcats) #working with factors
library(tidyverse) #manipulating data
library(knitr) #rmarkdown functions
library(mvabund) #for multivariate stats
library(gllvm) #for multivariate abundance
library(lattice) #fourth corner heatmap
library(corrplot) #co-occurrence matrix
library(gclus) #co-occurrence matrix
library(broom.mixed) #regression tables
library(grDevices) #colour palattes for ordiplot
```

```{r create-df}
#create survey count  

        #load item counts
        item <- read.csv(file="Data/2101_item.csv", 
                         header=T, sep=",") 
        
        #load events
        event <- read.csv(file="Data/2101_event.csv", 
                         header=T, sep=",") 
        
        #join event info to item count
        survey_count <- left_join(item, event, by="event_id")
        
        survey_count <- survey_count %>%
          dplyr::select(-event.tot, -event.wt, -vol, -hr, -note) %>%
          filter(item!="Pollution Rating") %>%
          mutate(event_item = paste(event_id, item, sep=" "))

        #summarise duplicate survey entries (this will lose one set of notes....)
        item_merge <- survey_count %>%
          group_by(event_item) %>%
          summarise(sum=sum(total)) %>%
         ungroup()

        #join survey count to the merged summaries
        survey_count <- item_merge %>%
          left_join(survey_count, by="event_item") %>%
          dplyr::select(-total) %>%
          unique()
        
#create abundance data with all possible debris items and zero values

      #count of items per unique event
      event_count <- survey_count %>%
        group_by(event_id, item) %>%
        summarise(sum=sum(sum)) %>%
        ungroup()

      #load AMDI code\
      AMDI_code <- read.csv(file="Data/200101_AMDI_code.csv", 
                       header=T, sep=",") 
      
      #create full list of possible items
      AMDI <- AMDI_code %>%
        filter(item_code_id != "LSTD1") %>% #remove pollution rating / microplastics
        dplyr::select(item.ex) #column of all possible item types
      
      
      #create a df of all possible items at all survey events, complete with zeros
      abund <- full_join(AMDI, event_count, by=c("item.ex" = "item"))
      
      #remove empty row
      abund <- abund[-11613, ]
      
      #data long to wide
      abund_wide <- spread(abund, item.ex, sum)
      
      #replace na values with 0
      abund_wide[is.na(abund_wide)] <- 0
        
      #transform back to long but now with the full items list and zero data
      abund_long <- melt(abund_wide, id.vars="event_id")
      
      #remove the zero event ID (how did that get there?)
      abund_long <- abund_long[abund_long$event_id != 0, ]
      
      #create event_item column for joining
      abund_long <- abund_long %>%
      mutate(event_item = paste(event_id, variable, sep=" "))

#join abundance data to survey notes and other columns
  df <- left_join(abund_long, survey_count, by="event_item") 
  
  df <- df %>%
    dplyr::select(-event_item, -event_id.y, -item, -sum) %>% #remove duplicate columns
    rename(event_id=event_id.x,
           item=variable,
           sum=value) %>% #rename columns
    arrange(event_id, Asset.ID) %>% #arrange by event so that missing values are aligned
    fill(Asset.ID, Cycle, date, covid) #fill in missing values to match survey data

  #clean up column classifications
  
  #reclassify columns to factor
    names <- c("event_id", "Asset.ID", "Cycle")
  
    df[,names] <- lapply(df[,names], factor)
  
  #reclassify date
    df$date <- dmy(df$date)

#join land use zone and LGA
    
    #load sites
        site <- read.csv(file="Data/200619_site.csv", 
                         header=T, sep=",") 
        
    #join LGA and luz to df
        df <- left_join(df, site, by = "Asset.ID")
        
    #remove unecessary columns
        df <- df %>%
          dplyr::select(-Site, -Latitude, -Longitude) 
     
#resolve duplicates in MC01, C5    
        dup <- df %>% 
          group_by(Asset.ID, Cycle, item) %>% #reconcile duplicates in MC01 Cycle 5
          summarise(sum=sum(sum)) %>%
          ungroup() %>%
          mutate(join = paste(Asset.ID, Cycle, item, sep=" "))
         
    # #check difference
    #      subsetdf <- df %>%
    #        dplyr::select(Asset.ID, Cycle, item, sum)
    #      
    #      setdiff(subsetdf, dup)
         
    #join C5 correction to df
         df <- df %>%
           mutate(join = paste(Asset.ID, Cycle, item, sep=" "))
         
    df <- dup %>% left_join(df, by="join") %>%
      dplyr::select(-join, -item.y, -sum.y, -Asset.ID.y, -Cycle.y) %>%
      filter(event_id != "23097") %>%
      rename(
          asset_id = Asset.ID.x, 
          cycle = Cycle.x,
          item = item.x,
          sum = sum.x,
          LUZ = Land.use.zone,
      ) %>%
      distinct()
    
    rm(abund, abund_long, abund_wide, dup, event_count, item_merge, survey_count)
```

```{r 4th-corner}

#Abundance
    #create abundance long format
     abund_long <- df %>%
        group_by(event_id, LUZ, item) %>% 
        summarise(sum=sum(sum)) %>% #total of each item type per survey event
      ungroup()
    
    #convert to data wide
      abund <- spread(abund_long, item, sum) 
    
      #convert survey event to rowname  
      length(unique(abund$event_id)) == nrow(abund) #checking for duplicates
      abund <- column_to_rownames(abund, var="event_id") #create rownames from survey event
      
      com <- abund[2:136]
      
      #removing debris items that are zero across all surveys
      com <- com[, which(colSums(com) != 0)]
      
#Environment
  #create survey event and filter zero sum surveys, 
    env <- df %>%
      group_by(event_id) %>%
      mutate(sum=sum(sum)) %>%
      filter(sum>0) %>%
      dplyr::select(event_id, covid, LUZ) %>%
      distinct()
    
    
    #convert survey event to rowname
  length(unique(env$event_id)) == nrow(env) #checking for duplicates
  env <- column_to_rownames(env, var="event_id") #create rownames from survey event
  #convert covid to numeric
  env$covid <- as.numeric(env$covid) #convert to numeric
  # #convert LUZ to numeric
  env$LUZ <- as.factor(env$LUZ) #convert character to factor with 4 levels
  env$LUZ <- as.numeric(env$LUZ) #convert factor to numeric
    
#Traits
  
  #create column of usable IDs to join
  items <- com %>%
    gather(item, sum) %>%
    dplyr::select(item) %>%
    unique()
  
  #create trait df with ID type as row and columns are fishing and dispersiveness
  TR <- df %>%
    group_by(item) %>%
    summarise(sum=sum(sum)) %>%
    left_join(AMDI_code, by=c("item"="item.ex")) %>%
    dplyr::select(mat, item) %>%
    inner_join(items, by="item") %>% #remove items with 0 count
    column_to_rownames(var="item") #create rownames from ID
  
  TR$mat <- as.factor(TR$mat)

#final variables
  y <- as.matrix(com)
  X <- scale(as.matrix(env))
  TR <- TR
  
```

```{r wide-format}
gllvm(y, family = "negative.binomial")

#model with environmental variables as predictors
fit_env <- gllvm(y, X, family="negative.binomial", 
                 formula = y ~ (covid + LUZ))
coefplot(fit_env)
```

